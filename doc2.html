<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Test Generation System Documentation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1 { color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }
        h2 { color: #34495e; margin-top: 30px; }
        h3 { color: #7f8c8d; }
        pre { background: #f4f4f4; padding: 15px; border-radius: 5px; overflow-x: auto; }
        code { background: #f4f4f4; padding: 2px 4px; border-radius: 3px; }
        .nav { background: #ecf0f1; padding: 15px; margin-bottom: 30px; border-radius: 5px; }
        .nav a { margin-right: 15px; text-decoration: none; color: #2980b9; }
        .nav a:hover { text-decoration: underline; }
        .agent-box { background: #f8f9fa; border-left: 4px solid #3498db; padding: 15px; margin: 15px 0; }
        .feature-list { background: #e8f5e8; padding: 15px; border-radius: 5px; }
        .warning { background: #fff3cd; border: 1px solid #ffeaa7; padding: 10px; border-radius: 5px; }
        .info { background: #d1ecf1; border: 1px solid #bee5eb; padding: 10px; border-radius: 5px; }
        table { border-collapse: collapse; width: 100%; margin: 15px 0; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
    </style>
</head>
<body>
    <h1>AI Test Generation System Documentation</h1>
    
    <div class="nav">
        <a href="#overview">Overview</a>
        <a href="#architecture">Architecture</a>
        <a href="#agents">Agents</a>
        <a href="#installation">Installation</a>
        <a href="#usage">Usage</a>
        <a href="#configuration">Configuration</a>
        <a href="#examples">Examples</a>
        <a href="#api">API Reference</a>
    </div>

    <section id="overview">
        <h2>Overview</h2>
        <p>The AI Test Generation System is a comprehensive, agentic approach to automatically generating high-quality test suites for Python codebases. It uses multiple specialized agents working together to analyze code, generate intelligent test strategies, and produce comprehensive test cases.</p>
        
        <div class="feature-list">
            <h3>Key Features</h3>
            <ul>
                <li>Multi-agent architecture with specialized roles</li>
                <li>Advanced code analysis with semantic understanding</li>
                <li>AI-powered test generation using Google Gemini</li>
                <li>Comprehensive test strategies (unit, integration, security, performance)</li>
                <li>Intelligent test data generation</li>
                <li>Dynamic analysis and coverage tracking</li>
                <li>Mutation testing for quality assessment</li>
                <li>Support for pytest, unittest, and nose2 frameworks</li>
            </ul>
        </div>
    </section>

    <section id="architecture">
        <h2>System Architecture</h2>
        <p>The system follows a multi-agent architecture where each agent has a specific responsibility:</p>
        
        <div class="agent-box">
            <h3>TestSuiteOrchestrator</h3>
            <p>Main coordinator that orchestrates all agents and manages the overall test generation workflow.</p>
        </div>

        <div class="agent-box">
            <h3>EnhancedCodeAnalysisAgent</h3>
            <p>Analyzes Python source code, extracts function metadata, calculates complexity, and identifies security-sensitive areas.</p>
        </div>

        <div class="agent-box">
            <h3>EnhancedTestStrategyAgent</h3>
            <p>Develops intelligent test strategies based on code analysis, including prioritization and test type selection.</p>
        </div>

        <div class="agent-box">
            <h3>EnhancedTestGenerationAgent</h3>
            <p>Generates actual test cases using AI-powered scenario generation and intelligent test data creation.</p>
        </div>

        <div class="agent-box">
            <h3>TestValidationAgent</h3>
            <p>Validates generated test cases for syntax, quality, and best practices compliance.</p>
        </div>

        <div class="agent-box">
            <h3>GeminiLLMAgent</h3>
            <p>Integrates with Google Gemini AI for semantic analysis and intelligent test scenario generation.</p>
        </div>
    </section>

    <section id="agents">
        <h2>Agent Details</h2>
        
        <h3>Code Analysis Capabilities</h3>
        <ul>
            <li>AST-based function extraction</li>
            <li>Complexity calculation (cyclomatic complexity)</li>
            <li>Security sensitivity detection</li>
            <li>Dependency analysis</li>
            <li>Exception handling detection</li>
            <li>Data flow analysis</li>
            <li>Side effect detection</li>
            <li>Risk score calculation</li>
        </ul>

        <h3>Test Strategy Features</h3>
        <ul>
            <li>Priority-based test ordering</li>
            <li>Adaptive coverage goals</li>
            <li>Security-focused test planning</li>
            <li>Integration test mapping</li>
            <li>Performance test identification</li>
            <li>Quality metrics definition</li>
        </ul>

        <h3>Test Generation Types</h3>
        <table>
            <tr>
                <th>Test Type</th>
                <th>Description</th>
                <th>Use Case</th>
            </tr>
            <tr>
                <td>UNIT</td>
                <td>Basic unit tests</td>
                <td>All functions</td>
            </tr>
            <tr>
                <td>INTEGRATION</td>
                <td>Integration tests</td>
                <td>Functions with dependencies</td>
            </tr>
            <tr>
                <td>EDGE_CASE</td>
                <td>Boundary condition tests</td>
                <td>Complex functions</td>
            </tr>
            <tr>
                <td>SECURITY</td>
                <td>Security-focused tests</td>
                <td>Security-sensitive functions</td>
            </tr>
            <tr>
                <td>PERFORMANCE</td>
                <td>Performance tests</td>
                <td>Performance-critical functions</td>
            </tr>
            <tr>
                <td>ERROR_HANDLING</td>
                <td>Exception handling tests</td>
                <td>Functions with error handling</td>
            </tr>
        </table>
    </section>

    <section id="installation">
        <h2>Installation</h2>
        
        <h3>Prerequisites</h3>
        <pre><code>Python 3.7+
pip install requirements</code></pre>

        <h3>Required Dependencies</h3>
        <pre><code>google-generativeai
python-dotenv
pytest (for pytest framework support)
unittest (built-in)
nose2 (for nose2 framework support)</code></pre>

        <h3>Optional Dependencies</h3>
        <pre><code>pynguin (for additional test generation)
hypothesis (for property-based testing)</code></pre>

        <div class="warning">
            <strong>Note:</strong> You'll need a Google Gemini API key for AI-powered features. The system will work without it but with reduced capabilities.
        </div>
    </section>

    <section id="usage">
        <h2>Usage</h2>
        
        <h3>Basic Command Line Usage</h3>
        <pre><code>python main.py path/to/your/python/files --output-dir generated_tests</code></pre>

        <h3>Advanced Usage</h3>
        <pre><code># Analyze specific files
python main.py file1.py file2.py --output-dir tests

# Set coverage target
python main.py src/ --coverage-target 0.90

# Specify test framework
python main.py src/ --framework pytest

# Use Gemini API key
python main.py src/ --api-key YOUR_API_KEY</code></pre>

        <h3>Environment Variables</h3>
        <pre><code># Create .env file
GEMINI_API_KEY=your_api_key_here</code></pre>

        <h3>Programmatic Usage</h3>
        <pre><code>from main import TestSuiteOrchestrator

config = {
    'gemini_api_key': 'your_api_key',
    'framework': TestFramework.PYTEST,
    'min_coverage': 0.85
}

orchestrator = TestSuiteOrchestrator(config)
test_suite = orchestrator.generate_comprehensive_test_suite(['path/to/file.py'])
</code></pre>
    </section>

    <section id="configuration">
        <h2>Configuration</h2>
        
        <h3>Configuration Parameters</h3>
        <table>
            <tr>
                <th>Parameter</th>
                <th>Type</th>
                <th>Default</th>
                <th>Description</th>
            </tr>
            <tr>
                <td>gemini_api_key</td>
                <td>string</td>
                <td>None</td>
                <td>Google Gemini API key</td>
            </tr>
            <tr>
                <td>framework</td>
                <td>TestFramework</td>
                <td>PYTEST</td>
                <td>Test framework to use</td>
            </tr>
            <tr>
                <td>min_coverage</td>
                <td>float</td>
                <td>0.8</td>
                <td>Minimum coverage percentage</td>
            </tr>
            <tr>
                <td>output_dir</td>
                <td>string</td>
                <td>generated_tests</td>
                <td>Output directory for tests</td>
            </tr>
        </table>

        <h3>Priority Levels</h3>
        <ul>
            <li><strong>CRITICAL</strong>: Security-sensitive, high-risk functions</li>
            <li><strong>HIGH</strong>: Complex functions with many dependencies</li>
            <li><strong>MEDIUM</strong>: Standard business logic functions</li>
            <li><strong>LOW</strong>: Simple utility functions</li>
        </ul>
    </section>

    <section id="examples">
        <h2>Examples</h2>
        
        <h3>Example 1: Basic Test Generation</h3>
        <pre><code># Generate tests for a single file
python main.py calculator.py

# This will analyze calculator.py and generate:
# - Unit tests for all functions
# - Edge case tests for complex functions
# - Security tests if applicable
# - Integration tests for functions with dependencies</code></pre>

        <h3>Example 2: Directory Analysis</h3>
        <pre><code># Analyze entire project
python main.py src/ --coverage-target 0.95 --framework pytest

# This will:
# - Recursively find all .py files in src/
# - Generate comprehensive test suite
# - Target 95% coverage
# - Use pytest framework</code></pre>

        <h3>Example 3: Security-Focused Testing</h3>
        <pre><code># For security-sensitive applications
python main.py auth_module.py payment_processor.py --api-key YOUR_KEY

# This will:
# - Use AI to identify security concerns
# - Generate security-specific test cases
# - Include input validation tests
# - Create SQL injection and XSS tests</code></pre>

        <div class="info">
            <strong>Tip:</strong> The system automatically detects security-sensitive functions based on naming patterns, dependencies, and semantic analysis.
        </div>
    </section>

    <section id="api">
        <h2>API Reference</h2>
        
        <h3>Core Classes</h3>
        
        <h4>TestSuiteOrchestrator</h4>
        <pre><code>class TestSuiteOrchestrator:
    def __init__(self, config: Dict[str, Any] = None)
    def generate_comprehensive_test_suite(self, file_paths: List[str]) -> TestSuite</code></pre>

        <h4>FunctionInfo</h4>
        <pre><code>@dataclass
class FunctionInfo:
    name: str
    file_path: str
    line_number: int
    parameters: List[Dict[str, Any]]
    return_type: Optional[str]
    docstring: Optional[str]
    complexity: int
    is_security_sensitive: bool
    dependencies: List[str]
    exceptions: List[str]
    side_effects: List[str]
    risk_score: float</code></pre>

        <h4>TestCase</h4>
        <pre><code>@dataclass
class TestCase:
    name: str
    test_type: TestType
    priority: Priority
    target_function: str
    test_code: str
    description: str
    quality_score: float
    maintainability_score: float</code></pre>

        <h4>TestSuite</h4>
        <pre><code>@dataclass
class TestSuite:
    name: str
    test_cases: List[TestCase]
    coverage_percentage: float
    quality_score: float
    security_coverage: float
    maintainability_score: float
    execution_time_estimate: float
    framework: TestFramework</code></pre>

        <h3>Enums</h3>
        
        <h4>TestType</h4>
        <pre><code>class TestType(Enum):
    UNIT = "unit"
    INTEGRATION = "integration"
    EDGE_CASE = "edge_case"
    SECURITY = "security"
    PERFORMANCE = "performance"
    ERROR_HANDLING = "error_handling"
    CONTRACT = "contract"
    MUTATION = "mutation"
    PROPERTY_BASED = "property_based"</code></pre>

        <h4>Priority</h4>
        <pre><code>class Priority(Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"</code></pre>

        <h4>TestFramework</h4>
        <pre><code>class TestFramework(Enum):
    PYTEST = "pytest"
    UNITTEST = "unittest"
    NOSE2 = "nose2"</code></pre>
    </section>

    <div style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #ddd; text-align: center; color: #666;">
        <p>AI Test Generation System - Comprehensive Documentation</p>
        <p>For questions or issues, refer to the source code or create an issue in the project repository.</p>
    </div>
</body>
</html>
